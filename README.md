Here's your **complete professional `README.md`** â€“ copy-paste this entire block into your `emotion-deepfake-detector/README.md` file:

---

```markdown
# Emotion-Aware Hybrid Model for Deepfake-Video Detection

A two-stream deepfake detection system that fuses spatial frame features with temporal emotion patterns. The model combines EfficientNetB0-based RGB frame embeddings with FER-extracted per-frame emotion probabilities, achieving strong performance on the CelebDF-V2 dataset.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shashankcheppala/emotion-deepfake-detector/blob/main/notebooks/deepfake_project.ipynb)

---

## ğŸ§  Architecture

- **Visual Stream:**  
  TimeDistributed EfficientNetB0 â†’ GlobalAveragePooling â†’ Conv1D temporal head  
- **Emotion Stream:**  
  8Ã—7 emotion matrix â†’ GlobalAveragePooling1D  
- **Fusion:**  
  Concatenate â†’ Dense(256â†’64) â†’ Dropout â†’ Sigmoid output  
- **Training:**  
  Binary Focal Loss (Î³=2, Î±=0.75), Warm-up + Cosine LR Decay, Mixed Precision

---

## ğŸ“Š Validation Results

| Model                  | Val AUC |
|------------------------|---------|
| Emotion-Only Logistic  | ~0.645  |
| FrameCNN (scratch)     | ~0.563  |
| Emotion RNN            | ~0.657  |
| VideoMAE + Logistic    | ~0.680  |
| **Hybrid CNN + Emotion** | **~0.850** |

---

## ğŸ“ Repository Structure

```

emotion-deepfake-detector/
â”œâ”€â”€ notebooks/           # Jupyter notebooks for experiments
â”‚   â””â”€â”€ deepfake\_project.ipynb
â”œâ”€â”€ src/                 # Core Python modules (preprocessing, training, evaluation)
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ training.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ models/              # Trained .keras model weights
â”œâ”€â”€ data/                # Sample or link-only (no raw datasets)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE

````

---

## ğŸ”§ Setup Instructions

```bash
git clone https://github.com/shashankcheppala/emotion-deepfake-detector.git
cd emotion-deepfake-detector
pip install -r requirements.txt
````

---

## ğŸš€ How to Run

### Training the Hybrid Model

```python
from src.training import train_hybrid_model

train_hybrid_model(
    frames_dir="path/to/frames",
    emotion_pkl="path/to/emotions.pkl",
    save_path="models/hybrid_model.keras"
)
```

---

## ğŸ“¦ Dataset

* **CelebDF-V2:**
  [https://github.com/yuezunli/Celeb-DF](https://github.com/yuezunli/Celeb-DF)

* Preprocessed:

  * 8Ã—224Ã—224 RGB frames per clip (.npy)
  * 8Ã—7 per-frame emotion vectors (.pkl)

---

## ğŸ“ˆ Features

* ğŸ§  Emotion-Aware Detection
* ğŸï¸ EfficientNetB0 + Conv1D for temporal consistency
* ğŸ“Š ROC, AUC, and full evaluation pipeline
* âš¡ Mixed Precision & Cosine Decay LR Scheduling
* ğŸ§ª Baselines: Emotion-only, CNN-only, RNN, VideoMAE+Logistic

---

## ğŸ‘¤ Author

**Shashank Cheppala**
M.S. in Data Analytics, University of Illinois Springfield
[GitHub](https://github.com/shashankcheppala) â€¢ [LinkedIn](https://www.linkedin.com/in/shashank-cheppala-6455ab1a4/)

---

## ğŸªª License

This repository is released under the [MIT License](LICENSE).

```

---

Let me know if you want me to generate `requirements.txt` based on the code you used in the project.
```
